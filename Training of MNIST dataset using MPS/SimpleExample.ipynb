{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook with Small examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorly==0.5.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorly==0.5.1) (1.5.2)\n",
      "Requirement already satisfied: nose in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorly==0.5.1) (1.3.7)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorly==0.5.1) (1.19.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorly==0.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 1 1 2 1 1 2 2]\n",
      "[2 1 1 1 1 1 2 1 2 1]\n",
      "[0 1 0] 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import gzip\n",
    "import math\n",
    "import os\n",
    "\n",
    "def make_dataset_easy():\n",
    "    Nt=8\n",
    "    data=np.zeros((Nt,3,3))\n",
    "\n",
    "    #White square on left\n",
    "    data[0]=np.array([[1,0,0],[1,0,0],[1,0,0]])\n",
    "    data[1]=np.array([[1,0,0],[0,0,0],[0,0,0]])\n",
    "    data[2]=np.array([[0,0,0],[1,0,0],[0,0,0]])\n",
    "    data[3]=np.array([[0,0,0],[0,0,0],[1,0,0]])\n",
    "\n",
    "    #White square on right\n",
    "    data[4]=np.array([[0,0,1],[0,0,1],[0,0,1]])\n",
    "    data[5]=np.array([[0,0,1],[0,0,0],[0,0,0]])\n",
    "    data[6]=np.array([[0,0,0],[0,0,1],[0,0,0]])\n",
    "    data[7]=np.array([[0,0,0],[0,0,0],[0,0,1]])\n",
    "\n",
    "    #Creation of the labels\n",
    "    y=np.array([[1,0],[1,0],[1,0],[1,0],[0,1],[0,1],[0,1],[0,1]])\n",
    "\n",
    "    return (data,y)\n",
    "\n",
    "def make_dataset_random(N,nbExample,nbClass):\n",
    "    np.random.seed(123)\n",
    "\n",
    "    #Creation of inputs\n",
    "    data=np.random.random_sample((nbExample,N))\n",
    "\n",
    "    #Creation of labels\n",
    "    y=np.zeros((nbExample,nbClass)) \n",
    "    for ex in range(nbExample):\n",
    "        y[ex,random.randint(0,nbClass-1)]=1\n",
    "\n",
    "    return (data,y)\n",
    "\n",
    "def load_MNIST_dataset(path):\n",
    "    f = gzip.open(f'{path}/external/train-images-idx3-ubyte.gz','r')\n",
    "\n",
    "    image_size = 28\n",
    "    num_images = 60000\n",
    "\n",
    "    f.read(16)\n",
    "    buf = f.read(image_size * image_size * num_images)\n",
    "    train_data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "    train_data = train_data.reshape(num_images, image_size, image_size)/256\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    #Test images\n",
    "    f = gzip.open(f'{path}/external/t10k-images-idx3-ubyte.gz','r')\n",
    "\n",
    "    image_size = 28\n",
    "    num_images = 10000\n",
    "\n",
    "    f.read(16)\n",
    "    buf = f.read(image_size * image_size * num_images)\n",
    "    test_data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "    test_data = test_data.reshape(num_images, image_size, image_size)/256\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    #Training labels\n",
    "\n",
    "    f = gzip.open(f'{path}/external/train-labels-idx1-ubyte.gz','r')\n",
    "\n",
    "    num_images = 60000\n",
    "\n",
    "    f.read(8)\n",
    "    buf = f.read(1 * num_images)\n",
    "    train_labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    #Test labels\n",
    "\n",
    "    f = gzip.open(f'{path}/external/t10k-labels-idx1-ubyte.gz','r')\n",
    "\n",
    "    num_images = 10000\n",
    "\n",
    "    f.read(8)\n",
    "    buf = f.read(1 * num_images)\n",
    "    test_labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    return (train_data , test_data , train_labels , test_labels)\n",
    "\n",
    "def convert_one_hot_encoding(labels):\n",
    "    #Retrieval of the number of labels\n",
    "    num_labels=labels.shape[0]\n",
    "\n",
    "    #Computation of the number of classes\n",
    "    num_class = np.max(labels) + 1\n",
    "    new_labels=np.zeros((num_labels,num_class),dtype=np.int64)\n",
    "\n",
    "    #Convertion of the labels\n",
    "    for i in range(num_labels):\n",
    "        new_labels[i,labels[i]]=1\n",
    "\n",
    "    return new_labels\n",
    "\n",
    "def make_MNIST_dataset_small(path):\n",
    "    train_data , test_data , train_labels , test_labels = load_MNIST_dataset(path)\n",
    "\n",
    "    #Training images\n",
    "    num_images = 60000\n",
    "\n",
    "    new_train_data=np.zeros((num_images,14,14))\n",
    "    for k in range(num_images):\n",
    "        for i in range(0,28,2):\n",
    "            for j in range(0,28,2):\n",
    "                new_train_data[k,int(i/2),int(j/2) ] = (train_data[k,i,j] + train_data[k,i+1,j] + train_data[k,i,j+1] + train_data[k,i+1,j+1])/4\n",
    "\n",
    "    #Training images\n",
    "    num_images = 10000\n",
    "\n",
    "    new_test_data=np.zeros((num_images,14,14))\n",
    "    for k in range(num_images):\n",
    "        for i in range(0,28,2):\n",
    "            for j in range(0,28,2):\n",
    "                new_test_data[k,int(i/2),int(j/2) ] = (test_data[k,i,j] + test_data[k,i+1,j] + test_data[k,i,j+1] + test_data[k,i+1,j+1])/4\n",
    "\n",
    "    \n",
    "    #Saving the pictures in the folder processed\n",
    "    np.save(f'{path}/processed/small_train_images.npy',new_train_data)\n",
    "    np.save(f'{path}/processed/small_test_images.npy',new_test_data)\n",
    "\n",
    "    return (new_train_data , new_test_data , train_labels , test_labels)\n",
    "\n",
    "def load_MNIST_dataset_small(path):\n",
    "    train_data = np.load(f'{path}/processed/small_train_images.npy')\n",
    "    test_data = np.load(f'{path}/processed/small_test_images.npy')\n",
    "    f = gzip.open(f'{path}/external/train-labels-idx1-ubyte.gz','r')\n",
    "\n",
    "    num_images = 60000\n",
    "\n",
    "    f.read(8)\n",
    "    buf = f.read(1 * num_images)\n",
    "    train_labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    #Test labels\n",
    "\n",
    "    f = gzip.open(f'{path}/external/t10k-labels-idx1-ubyte.gz','r')\n",
    "\n",
    "    num_images = 10000\n",
    "\n",
    "    f.read(8)\n",
    "    buf = f.read(1 * num_images)\n",
    "    test_labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    return (train_data , test_data , train_labels , test_labels)\n",
    "    \n",
    "def load_subpart_MNIST_dataset_small(path,digits):\n",
    "    train_data , test_data , train_labels , test_labels = load_MNIST_dataset_small(path)\n",
    "\n",
    "    train_index = [i for i in range(len(train_data)) if train_labels[i] in digits]\n",
    "    test_index = [i for i in range(len(test_data)) if test_labels[i] in digits]\n",
    "\n",
    "    return (train_data[train_index] , test_data[test_index] , train_labels[train_index] , test_labels[test_index])\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path = \"data\"\n",
    "    digits=[2,1]\n",
    "    train_data , test_data , train_labels , test_labels = load_subpart_MNIST_dataset_small(path,digits)\n",
    "    print(train_labels[0:10])\n",
    "    print(test_labels[0:10])\n",
    "\n",
    "    new_labels = convert_one_hot_encoding(train_labels)\n",
    "    print(new_labels[0],train_labels[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(x):\n",
    "    return np.array([np.cos((np.pi*x)/2),np.sin((np.pi*x)/2)])\n",
    "\n",
    "def Phi(img):\n",
    "    return phi(img.reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### U1 #####\n",
      "(2, 10, 10)\n",
      "##### V1 #####\n",
      "(2, 10, 20)\n",
      "##### U2 #####\n",
      "(2, 10, 10)\n",
      "##### V2 #####\n",
      "(2, 10, 20)\n"
     ]
    }
   ],
   "source": [
    "import tensorly as tl\n",
    "def direction(u,s,v,sel,pos0,bond_dim,nmethod):\n",
    "    if(nmethod==1):\n",
    "        if(sel>pos0):\n",
    "            v = v[0:bond_dim,:]  ; u =  u[:,0:bond_dim] @ np.diag(s)\n",
    "        else:\n",
    "            v = np.diag(s) @ v[0:bond_dim,:]  ; u =  u[:,0:bond_dim]\n",
    "    if(nmethod==2):\n",
    "        if(sel<pos0):\n",
    "            v = v[0:bond_dim,:]  ; u =  u[:,0:bond_dim] @ np.diag(s)\n",
    "        else:\n",
    "            v = np.diag(s) @ v[0:bond_dim,:]  ; u =  u[:,0:bond_dim]\n",
    "    return (u,v)\n",
    "\n",
    "def SVD_matB(B,sel,pos0,maxalpha,cutoff,nmethod):\n",
    "    u, s, v = np.linalg.svd(B,full_matrices=False)\n",
    "    bond_dim=min(np.sum(s>cutoff),maxalpha)\n",
    "    s=s[0:bond_dim]\n",
    "    u , v = direction(u,s,v,sel,pos0,bond_dim,nmethod)\n",
    "    return (u , v, bond_dim)\n",
    "\n",
    "def SVD_B(sel,pos0,B,posL,N,maxalpha,cutoff,nmethod):\n",
    "    dim=B.shape\n",
    "    if(sel==0 or (sel==1 and sel>pos0) ):\n",
    "        B=B.reshape(dim[0],dim[1]*dim[2])\n",
    "        u, v , bond_dim = SVD_matB(B,sel,pos0,maxalpha,cutoff,nmethod)\n",
    "        v= v.reshape(bond_dim,2,dim[2]).transpose((1,0,2))\n",
    "    elif( (sel==posL-1 and sel< pos0) or (sel==posL and sel> pos0) ):\n",
    "        B=B.reshape(dim[0]*dim[1],dim[2]*dim[3]*dim[4])\n",
    "        u, v , bond_dim = SVD_matB(B,sel,pos0,maxalpha,cutoff,nmethod)\n",
    "        u = u.reshape(2,dim[1],bond_dim)\n",
    "        v= v.reshape(bond_dim,2,dim[3],dim[4]).transpose((1,0,2,3))\n",
    "    elif( (sel==N-2 and sel< pos0 )or sel==N-1):\n",
    "        B=B.reshape(dim[0]*dim[1],dim[2])\n",
    "        u, v , bond_dim= SVD_matB(B,sel,pos0,maxalpha,cutoff,nmethod)\n",
    "        u = u.reshape(2,dim[1],bond_dim)\n",
    "        v= v.reshape(bond_dim,dim[2]).transpose((1,0))\n",
    "    elif( (sel==posL and sel< pos0) or (sel==posL+1 and sel > pos0) ):\n",
    "        B=B.reshape(dim[0]*dim[1]*dim[2],dim[3]*dim[4])\n",
    "        u, v , bond_dim= SVD_matB(B,sel,pos0,maxalpha,cutoff,nmethod)\n",
    "        u = u.reshape(2,dim[1],dim[2],bond_dim).transpose((0,1,3,2))\n",
    "        v= v.reshape(bond_dim,2,dim[4]).transpose((1,0,2))\n",
    "    else:\n",
    "        B=B.reshape(dim[0]*dim[1],dim[2]*dim[3])\n",
    "        u, v , bond_dim= SVD_matB(B,sel,pos0,maxalpha,cutoff,nmethod)\n",
    "        u = u.reshape(2,dim[1],bond_dim)\n",
    "        v= v.reshape(bond_dim,2,dim[3]).transpose((1,0,2))\n",
    "    return (u,v)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #test 1\n",
    "    sel=5 ; pos0=6 ; posL=8 ; N=9 ; maxalpha = 10 ; cutoff=10**(-10)\n",
    "    B=np.random.randn(2,10,2,20)\n",
    "    u1 , v1 = SVD_B(sel,pos0,B,posL,N,maxalpha,cutoff,1)\n",
    "    u2 , v2 = SVD_B(sel,pos0,B,posL,N,maxalpha,cutoff,2)\n",
    "    print(\"##### U1 #####\")\n",
    "    print(u1.shape) \n",
    "    print(\"##### V1 #####\")\n",
    "    print(v1.shape)\n",
    "    print(\"##### U2 #####\")\n",
    "    print(u2.shape)\n",
    "    print(\"##### V2 #####\") \n",
    "    print(v2.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DMRG_creation_B_Atilde(W,sel,pos0):\n",
    "        A_tilde=W.copy() ; B_vec=[] ; B_vec.append(A_tilde.pop(sel))\n",
    "        if(sel<pos0) : B_vec.append(A_tilde.pop(pos0-1)) \n",
    "        else : B_vec.append(A_tilde.pop(pos0))\n",
    "                       \n",
    "        if(sel<pos0):\n",
    "            if(sel==0):\n",
    "                B=tl.tenalg.contract(B_vec[0],1,B_vec[1],1)\n",
    "            else:\n",
    "                B=tl.tenalg.contract(B_vec[0],2,B_vec[1],1)\n",
    "\n",
    "        if(sel>pos0):\n",
    "            if(sel==1):\n",
    "                B=tl.tenalg.contract(B_vec[1],1,B_vec[0],1)\n",
    "            else:\n",
    "                B=tl.tenalg.contract(B_vec[1],2,B_vec[0],1)\n",
    "\n",
    "        return (B,A_tilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DMRG_creation_phi_tilde12(A_tilde,Phi,sel,pos0,n,Min,N,nbTraining):\n",
    "    Phi_tilde1=0 ; Phi_tilde2=0\n",
    "\n",
    "    #Initialization of the static variables of the function (needeed so that the algorithm scales linearly with N)\n",
    "    if(n==0 and sel == 0 and pos0 == 1):\n",
    "        DMRG_creation_phi_tilde12.Phi_tilde1_table_to_right=[0]*nbTraining\n",
    "        DMRG_creation_phi_tilde12.Phi_tilde1_table_to_left=[[0 for i in range(N-2)] for j in range(nbTraining)]\n",
    "        DMRG_creation_phi_tilde12.Phi_tilde2_table_to_right=[[0 for i in range(N-2)] for j in range(nbTraining)]\n",
    "        DMRG_creation_phi_tilde12.Phi_tilde2_table_to_left=[0]*nbTraining\n",
    "    \n",
    "    ##Construction of Phi_tilde1 to the right\n",
    "    if(sel==1 and sel<pos0):\n",
    "        DMRG_creation_phi_tilde12.Phi_tilde1_table_to_right[n]=tl.tenalg.mode_dot(A_tilde[0],Phi[:,0],0) #contractMPS(A_tilde[0:Min],Phi[:,:Min])\n",
    "        Phi_tilde1=DMRG_creation_phi_tilde12.Phi_tilde1_table_to_right[n]\n",
    "\n",
    "    if(sel!=0 and sel!=1 and sel<pos0):\n",
    "        DMRG_creation_phi_tilde12.Phi_tilde1_table_to_right[n]=tl.tenalg.contract(A_tilde[Min-1],1,DMRG_creation_phi_tilde12.Phi_tilde1_table_to_right[n],0)\n",
    "        DMRG_creation_phi_tilde12.Phi_tilde1_table_to_right[n]=tl.tenalg.mode_dot(DMRG_creation_phi_tilde12.Phi_tilde1_table_to_right[n],Phi[:,Min-1],0)\n",
    "        Phi_tilde1=DMRG_creation_phi_tilde12.Phi_tilde1_table_to_right[n]\n",
    "\n",
    "    ##Construction of Phi_tilde1 to the left\n",
    "    if(sel==(N-1)):\n",
    "        DMRG_creation_phi_tilde12.Phi_tilde1_table_to_left[n][0]=tl.tenalg.mode_dot(A_tilde[0],Phi[:,0],0)\n",
    "        for i in range(1,N-2) :\n",
    "            DMRG_creation_phi_tilde12.Phi_tilde1_table_to_left[n][i]=tl.tenalg.contract(A_tilde[i],1,DMRG_creation_phi_tilde12.Phi_tilde1_table_to_left[n][i-1],0)\n",
    "            DMRG_creation_phi_tilde12.Phi_tilde1_table_to_left[n][i]=tl.tenalg.mode_dot(DMRG_creation_phi_tilde12.Phi_tilde1_table_to_left[n][i],Phi[:,i],0)\n",
    "        Phi_tilde1=DMRG_creation_phi_tilde12.Phi_tilde1_table_to_left[n][N-3]\n",
    "\n",
    "    if(sel>pos0 and  not(sel==1 and sel>pos0)):\n",
    "        Phi_tilde1=DMRG_creation_phi_tilde12.Phi_tilde1_table_to_left[n][sel-2]\n",
    "\n",
    "    ##Construction of Phi_tilde2 to the right\n",
    "    if(sel==0):\n",
    "        DMRG_creation_phi_tilde12.Phi_tilde2_table_to_right[n][N-3]=tl.tenalg.mode_dot(A_tilde[N-3],Phi[:,N-3],0)\n",
    "        for i in range(N-4,-1,-1) :\n",
    "            DMRG_creation_phi_tilde12.Phi_tilde2_table_to_right[n][i]=tl.tenalg.contract(A_tilde[i],2,DMRG_creation_phi_tilde12.Phi_tilde2_table_to_right[n][i+1],0)\n",
    "            DMRG_creation_phi_tilde12.Phi_tilde2_table_to_right[n][i]=tl.tenalg.mode_dot(DMRG_creation_phi_tilde12.Phi_tilde2_table_to_right[n][i],Phi[:,i],0)\n",
    "        Phi_tilde2=DMRG_creation_phi_tilde12.Phi_tilde2_table_to_right[n][0]\n",
    "\n",
    "    if(sel!=0 and sel!=(N-2) and sel<pos0):\n",
    "        Phi_tilde2=DMRG_creation_phi_tilde12.Phi_tilde2_table_to_right[n][sel]\n",
    "\n",
    "    ##Construction of Phi_tilde2 to the left\n",
    "    if(sel==N-2 and sel>pos0):\n",
    "        DMRG_creation_phi_tilde12.Phi_tilde2_table_to_left[n]=tl.tenalg.mode_dot(A_tilde[N-3],Phi[:,N-3],0)\n",
    "        Phi_tilde2=DMRG_creation_phi_tilde12.Phi_tilde2_table_to_left[n]\n",
    "\n",
    "    if(sel != N-1 and sel!=N-2 and sel>pos0):\n",
    "        DMRG_creation_phi_tilde12.Phi_tilde2_table_to_left[n]=tl.tenalg.contract(A_tilde[sel-1],2,DMRG_creation_phi_tilde12.Phi_tilde2_table_to_left[n],0)\n",
    "        DMRG_creation_phi_tilde12.Phi_tilde2_table_to_left[n]=tl.tenalg.mode_dot(DMRG_creation_phi_tilde12.Phi_tilde2_table_to_left[n],Phi[:,sel-1],0)\n",
    "        Phi_tilde2=DMRG_creation_phi_tilde12.Phi_tilde2_table_to_left[n]\n",
    "        \n",
    "    return (Phi_tilde1,Phi_tilde2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DMRG_creation_Phi_tilde(Phi_tilde1,Phi_tilde2,si,sel,pos0,posL,N):\n",
    "    if(sel==0 or (sel==1 and sel>pos0) ):\n",
    "        Phi_tilde=np.multiply.outer(si[:,1],Phi_tilde2) #Phi_tilde2(alpha2,l) => Phi_tilde(s2,alpha2,l)\n",
    "        Phi_tilde=np.multiply.outer(si[:,0],Phi_tilde) #=> Phi_tilde(s1,s2,alpha2,l)\n",
    "    elif( (sel==posL-1 and sel< pos0) or (sel==posL and sel> pos0) ):\n",
    "        Phi_tilde=np.multiply.outer(si[:,0],Phi_tilde1) #=> Phi_tilde1(alpha(i-1)) => Phi_tilde1(si,alpha(i-1))\n",
    "        Phi_tilde=np.multiply.outer(Phi_tilde,si[:,1]) #=> Phi_tilde(si,alpha(i-1),s(i+1))\n",
    "        Phi_tilde=np.multiply.outer(Phi_tilde,Phi_tilde2) #=>Phi_tilde(si,alpha(i-1),s(i+1),alpha(i+1))\n",
    "    elif( (sel==posL and sel< pos0) or (sel==posL+1 and sel > pos0)  ):\n",
    "        Phi_tilde=np.multiply.outer(si[:,0],Phi_tilde1) #=> Phi_tilde1(alpha(i-1)) => Phi_tilde1(si,alpha(i-1))\n",
    "        Phi_tilde=np.multiply.outer(Phi_tilde,si[:,1]) #=> Phi_tilde(si,alpha(i-1),s(i+1))\n",
    "        Phi_tilde=np.multiply.outer(Phi_tilde,Phi_tilde2) #=>Phi_tilde(si,alpha(i-1),s(i+1),alpha(i+1))\n",
    "    elif( (sel==N-2 and sel<pos0 ) or sel==N-1):\n",
    "        Phi_tilde=np.multiply.outer(si[:,0],Phi_tilde1) #Phi_tilde1(alpha(N-2),l) =>Phi_tilde1(s(N-1),alpha(N-2),l)\n",
    "        Phi_tilde=np.multiply.outer(Phi_tilde,si[:,1]) #=> Phi_tilde(s(N-1),alpha(N-2),l,sN)\n",
    "    else:\n",
    "        Phi_tilde=np.multiply.outer(si[:,0],Phi_tilde1) #=> Phi_tilde1(alpha(i-1)) => Phi_tilde1(si,alpha(i-1))\n",
    "        Phi_tilde=np.multiply.outer(Phi_tilde,si[:,1]) #=> Phi_tilde(si,alpha(i-1),s(i+1))\n",
    "        Phi_tilde=np.multiply.outer(Phi_tilde,Phi_tilde2) #=>Phi_tilde(si,alpha(i-1),s(i+1),alpha(i+1),l)\n",
    "    return Phi_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DMRG_An_bn(Phi_tilde,Phi_tilde1,Phi_tilde2,si,sel,pos0,posL,N,y):\n",
    "    temp1=si[:,0].reshape(2,1)\n",
    "    An=np.dot(temp1,temp1.T)\n",
    "\n",
    "    #Computation of the outer product for the second pixel\n",
    "    temp1=si[:,1].reshape(2,1)\n",
    "    An=np.multiply.outer(An,np.dot(temp1,temp1.T))\n",
    "    \n",
    "    #Computation of An and bn \n",
    "    if(sel==0 or (sel==1 and sel>pos0) ):\n",
    "        temp2=np.dot(Phi_tilde2,Phi_tilde2.T)\n",
    "        An=np.multiply.outer(An,temp2) #An -> (s1,s1,s2,s2,alpha2,alpha2)\n",
    "        bn=tl.tenalg.mode_dot(Phi_tilde,y,3)\n",
    "    elif( (sel==posL-1 and sel< pos0) or (sel==posL and sel> pos0) ):\n",
    "        Phi_tilde1=Phi_tilde1.reshape(Phi_tilde1.shape[0],1) ; Phi_tilde2=Phi_tilde2.reshape(Phi_tilde2.shape[0],1)\n",
    "        temp2=np.dot(Phi_tilde1,Phi_tilde1.T)\n",
    "        An=np.multiply.outer(An,temp2)\n",
    "        temp2=np.dot(Phi_tilde2,Phi_tilde2.T)\n",
    "        An=np.multiply.outer(An,temp2) #An -> (sj,sj,sj+1,sj+1,alphaj-1,alphaj-1,alphaj+1,alphaj+1)\n",
    "        An=An.transpose((0,1,4,5,2,3,6,7)) #An -> (sj,sj,alphaj-1,alphaj-1,sj+1,sj+1,alphaj+1,alphaj+1)\n",
    "        bn=np.multiply.outer(Phi_tilde,y)\n",
    "    elif( (sel==posL and sel< pos0) or (sel==posL+1 and sel > pos0)  ):\n",
    "        Phi_tilde1=Phi_tilde1.reshape(Phi_tilde1.shape[0],1) ; Phi_tilde2=Phi_tilde2.reshape(Phi_tilde2.shape[0],1)\n",
    "        temp2=np.dot(Phi_tilde1,Phi_tilde1.T)\n",
    "        An=np.multiply.outer(An,temp2)\n",
    "        temp2=np.dot(Phi_tilde2,Phi_tilde2.T)\n",
    "        An=np.multiply.outer(An,temp2) #An -> (sj,sj,sj+1,sj+1,alphaj-1,alphaj-1,alphaj+1,alphaj+1)\n",
    "        An=An.transpose((0,1,4,5,2,3,6,7)) #An -> (sj,sj,alphaj-1,alphaj-1,sj+1,sj+1,alphaj+1,alphaj+1)\n",
    "        bn=np.multiply.outer(Phi_tilde,y)\n",
    "        bn=bn.transpose((0,1,4,2,3))\n",
    "    elif( (sel==N-2 and sel<pos0 ) or sel==N-1):\n",
    "        temp2=np.dot(Phi_tilde1,Phi_tilde1.T)\n",
    "        An=np.multiply.outer(An,temp2) #An -> (sN-1,sN-1,sN,sN,alphaN-2,alphaN-2)\n",
    "        An=An.transpose((0,1,4,5,2,3)) #An -> (sN-1,sN-1,alphaN-2,alphaN-2,sN,sN)\n",
    "        bn=tl.tenalg.mode_dot(Phi_tilde,y,2)\n",
    "    else:\n",
    "        if(sel<posL):\n",
    "            Phi_tilde1=Phi_tilde1.reshape(Phi_tilde1.shape[0],1)\n",
    "        else:\n",
    "            Phi_tilde2=Phi_tilde2.reshape(Phi_tilde2.shape[0],1)\n",
    "        temp2=np.dot(Phi_tilde1,Phi_tilde1.T)\n",
    "        An=np.multiply.outer(An,temp2)\n",
    "        temp2=np.dot(Phi_tilde2,Phi_tilde2.T)\n",
    "        An=np.multiply.outer(An,temp2) #An -> (s2,s2,s3,s3,alpha1,alpha1,alpha3,alpha3)\n",
    "        An=An.transpose((0,1,4,5,2,3,6,7)) #An -> (s2,s2,alpha1,alpha1,s3,s3,alpha3,alpha3)\n",
    "        if(sel<posL):\n",
    "            bn=tl.tenalg.mode_dot(Phi_tilde,y,4)\n",
    "        else:\n",
    "            bn=tl.tenalg.mode_dot(Phi_tilde,y,2)\n",
    "    return (An,bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DMRG_compute_stuff_gradient(Phi_tilde1,Phi_tilde2,si,sel,pos0,posL,N,y):\n",
    "    #Computation of Phi_tilde\n",
    "    Phi_tilde = DMRG_creation_Phi_tilde(Phi_tilde1,Phi_tilde2,si,sel,pos0,posL,N)\n",
    "\n",
    "    #Computation of An and bn\n",
    "    An,bn = DMRG_An_bn(Phi_tilde,Phi_tilde1,Phi_tilde2,si,sel,pos0,posL,N,y)\n",
    "\n",
    "    return (An,bn,Phi_tilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DMRG_compute_cost(B,Phi_tilde,y,sel,pos0,posL,N,loss_function,eps=10**(-10)):\n",
    "    if(sel==0 or (sel==1 and sel>pos0) ):\n",
    "        fl=tl.tenalg.contract(B,(0,1,2),Phi_tilde,(0,1,2))\n",
    "    elif( (sel==posL-1 and sel< pos0) or (sel==posL and sel> pos0) ):\n",
    "        fl=tl.tenalg.contract(B,(0,1,2,3),Phi_tilde,(0,1,2,3))\n",
    "    elif( (sel==posL and sel< pos0) or (sel==posL+1 and sel > pos0)  ):\n",
    "        fl=tl.tenalg.contract(B,(0,1,3,4),Phi_tilde,(0,1,2,3))\n",
    "    elif( (sel==N-2 and sel<pos0 ) or sel==N-1):\n",
    "        fl=tl.tenalg.contract(B,(0,1,2),Phi_tilde,(0,1,3))\n",
    "    else:\n",
    "        if(sel>posL):\n",
    "            fl=tl.tenalg.contract(B,(0,1,2,3),Phi_tilde,(0,1,3,4))\n",
    "        else:\n",
    "            fl=tl.tenalg.contract(B,(0,1,2,3),Phi_tilde,(0,1,2,3))\n",
    "    \n",
    "    #Computation of the loss\n",
    "    if loss_function ==\"quadratic\":\n",
    "        cost = (1/2)*np.power(fl-y,2)\n",
    "    elif loss_function == \"cross-entropy\":\n",
    "        cost = -y*np.log(np.exp(fl)/(sum(np.exp(fl)))+eps)\n",
    "    elif loss_function ==\"log-quadratic\":\n",
    "        cost = (1/2)*np.log(np.power(fl-y,2)+1)\n",
    "\n",
    "    #Summation over labels of the loss \n",
    "    return sum(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DMRG_compute_gradient(A,b,B,sel,pos0,posL,N,Phi_tilde=[],loss_function=\"quadratic\",label=[],eps=10**(-16)):\n",
    "    if(loss_function == \"quadratic\"):\n",
    "        if(sel==0 or (sel==1 and sel>pos0) ):\n",
    "            gradB=tl.tenalg.contract(A,(0,2,4),B,(0,1,2))-b\n",
    "        elif( (sel==posL-1 and sel< pos0) or (sel==posL and sel> pos0) ):\n",
    "            gradB=tl.tenalg.contract(A,(0,2,4,6),B,(0,1,2,3))-b \n",
    "        elif( (sel==posL and sel< pos0) or (sel==posL+1 and sel > pos0)  ):\n",
    "            gradB=tl.tenalg.contract(A,(0,2,4,6),B,(0,1,3,4)).transpose((0,1,4,2,3))-b \n",
    "        elif( (sel==N-2 and sel<pos0 ) or sel==N-1):\n",
    "            gradB=tl.tenalg.contract(A,(0,2,4),B,(0,1,2))-b\n",
    "        else:\n",
    "            gradB=tl.tenalg.contract(A,(0,2,4,6),B,(0,1,2,3))-b\n",
    "    elif(loss_function == \"cross-entropy\"):\n",
    "        gradB=0\n",
    "        for i in range(len(Phi_tilde)):\n",
    "            elem=Phi_tilde[i]\n",
    "            y=label[i,:]\n",
    "            if(sel==0 or (sel==1 and sel>pos0) ):\n",
    "                fl=tl.tenalg.contract(B,(0,1,2),elem,(0,1,2))\n",
    "                gradf=np.exp(fl)/(sum(np.exp(fl))+eps)-y\n",
    "                gradB+=tl.tenalg.mode_dot(elem,gradf,3) #=> gradB(s1,s2,alpha2)\n",
    "            elif( (sel==posL-1 and sel< pos0) or (sel==posL and sel> pos0) ):\n",
    "                fl=tl.tenalg.contract(B,(0,1,2,3),elem,(0,1,2,3))\n",
    "                gradf=np.exp(fl)/(sum(np.exp(fl))+eps)-y\n",
    "                gradB+=np.multiply.outer(elem,gradf) #gradB(si,alpha(i-1),s(i+1),alpha(i+1),l)\n",
    "            elif( (sel==posL and sel< pos0) or (sel==posL+1 and sel > pos0)  ):\n",
    "                fl=tl.tenalg.contract(B,(0,1,3,4),elem,(0,1,2,3))\n",
    "                gradf=np.exp(fl)/(sum(np.exp(fl))+eps)-y\n",
    "                gradf=np.multiply.outer(elem,gradf) #=>gradf(si,alpha(i-1),s(i+1),alpha(i+1),l)\n",
    "                gradB+=gradf.transpose((0,1,4,2,3)) #=>gradB(si,alpha(i-1),l,s(i+1),alpha(i+1))\n",
    "            elif( (sel==N-2 and sel<pos0 ) or sel==N-1):\n",
    "                fl=tl.tenalg.contract(B,(0,1,2),elem,(0,1,3))\n",
    "                gradf=np.exp(fl)/(sum(np.exp(fl))+eps)-y\n",
    "                gradB+=tl.tenalg.mode_dot(elem,gradf,2) #=> gradB(s(N-1),alpha(N-2),sN)\n",
    "            else:\n",
    "                if(sel>posL):\n",
    "                    fl=tl.tenalg.contract(B,(0,1,2,3),elem,(0,1,3,4))\n",
    "                    gradf=np.exp(fl)/(sum(np.exp(fl))+eps)-y\n",
    "                    gradB+=tl.tenalg.mode_dot(elem,gradf,2) #gradB(si,alpha(i-1),s(i+1),alpha(i+1))\n",
    "                else:\n",
    "                    fl=tl.tenalg.contract(B,(0,1,2,3),elem,(0,1,2,3))\n",
    "                    gradf=np.exp(fl)/(sum(np.exp(fl))+eps)-y\n",
    "                    gradB+=tl.tenalg.mode_dot(elem,gradf,4) #gradB(si,alpha(i-1),s(i+1),alpha(i+1))\n",
    "    elif(loss_function == \"log-quadratic\"):\n",
    "        gradB=0\n",
    "        for i in range(len(Phi_tilde)):\n",
    "            elem=Phi_tilde[i]\n",
    "            y=label[i,:]\n",
    "            if(sel==0 or (sel==1 and sel>pos0) ):\n",
    "                fl=tl.tenalg.contract(B,(0,1,2),elem,(0,1,2))\n",
    "                gradf=(fl-y)/(np.power(fl-y,2)+1)\n",
    "                gradB+=tl.tenalg.mode_dot(elem,gradf,3) #=> gradB(s1,s2,alpha2)\n",
    "            elif( (sel==posL-1 and sel< pos0) or (sel==posL and sel> pos0) ):\n",
    "                fl=tl.tenalg.contract(B,(0,1,2,3),elem,(0,1,2,3))\n",
    "                gradf=(fl-y)/(np.power(fl-y,2)+1)\n",
    "                gradB+=np.multiply.outer(elem,gradf) #gradB(si,alpha(i-1),s(i+1),alpha(i+1),l)\n",
    "            elif( (sel==posL and sel< pos0) or (sel==posL+1 and sel > pos0)  ):\n",
    "                fl=tl.tenalg.contract(B,(0,1,3,4),elem,(0,1,2,3))\n",
    "                gradf=(fl-y)/(np.power(fl-y,2)+1)\n",
    "                gradf=np.multiply.outer(elem,gradf) #=>gradf(si,alpha(i-1),s(i+1),alpha(i+1),l)\n",
    "                gradB+=gradf.transpose((0,1,4,2,3)) #=>gradB(si,alpha(i-1),l,s(i+1),alpha(i+1))\n",
    "            elif( (sel==N-2 and sel<pos0 ) or sel==N-1):\n",
    "                fl=tl.tenalg.contract(B,(0,1,2),elem,(0,1,3))\n",
    "                gradf=(fl-y)/(np.power(fl-y,2)+1)\n",
    "                gradB+=tl.tenalg.mode_dot(elem,gradf,2) #=> gradB(s(N-1),alpha(N-2),sN)\n",
    "            else:\n",
    "                if(sel>posL):\n",
    "                    fl=tl.tenalg.contract(B,(0,1,2,3),elem,(0,1,3,4))\n",
    "                    gradf=(fl-y)/(np.power(fl-y,2)+1)\n",
    "                    gradB+=tl.tenalg.mode_dot(elem,gradf,2) #gradB(si,alpha(i-1),s(i+1),alpha(i+1))\n",
    "                else:\n",
    "                    fl=tl.tenalg.contract(B,(0,1,2,3),elem,(0,1,2,3))\n",
    "                    gradf=(fl-y)/(np.power(fl-y,2)+1)\n",
    "                    gradB+=tl.tenalg.mode_dot(elem,gradf,4) #gradB(si,alpha(i-1),s(i+1),alpha(i+1))\n",
    "    \n",
    "    return gradB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #test de la fonction creation_B_Atilde\n",
    "    t1=np.array([[1,0],[0,4]])\n",
    "    t2=np.array([[[1,0],[0,1]],[[2,0],[0,0]]])\n",
    "    t3=np.array([[0,1],[2,3]])\n",
    "    W=[t1,t2,t3]\n",
    "    sel=1 ; pos0=2\n",
    "    B , A_tilde = DMRG_creation_B_Atilde(W,sel,pos0)\n",
    "\n",
    "    #test de la fonction DMRG_creation_phi_tilde\n",
    "    n=0 ; Min=min(sel,pos0) ; N=9 ; nbTraining=30 ; posL=2\n",
    "    p1=np.array([1,0]) ; p2=np.array([0,2]) ; p3=np.array([1,1])\n",
    "    Phi=np.array([p1,p2,p3]).T\n",
    "\n",
    "#     (Phi_tilde1,Phi_tilde2) = DMRG_creation_phi_tilde12(A_tilde,Phi,sel,pos0,n,Min,N,nbTraining)\n",
    "\n",
    "#     print(Phi_tilde1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGD_creation_phi_tilde(A_tilde,Phi,sel,n,N,nbTraining):\n",
    "    Phi_tilde1 = 0 ; Phi_tilde2 = 0 \n",
    "\n",
    "    if(n==0 and sel == 0):\n",
    "        AGD_creation_phi_tilde.Phi_tilde1_table=[0]*nbTraining\n",
    "        AGD_creation_phi_tilde.Phi_tilde2_table=[[0 for i in range(N-1)] for j in range(nbTraining)]\n",
    "\n",
    "    #Construction of phi_tilde1\n",
    "    if(sel==1):\n",
    "        AGD_creation_phi_tilde.Phi_tilde1_table[n]=tl.tenalg.mode_dot(A_tilde[0],Phi[:,0],0) \n",
    "        Phi_tilde1=AGD_creation_phi_tilde.Phi_tilde1_table[n]\n",
    "\n",
    "    if(sel!=0 and sel!=1):\n",
    "        AGD_creation_phi_tilde.Phi_tilde1_table[n]=tl.tenalg.mode_dot(A_tilde[sel-1],AGD_creation_phi_tilde.Phi_tilde1_table[n],1)\n",
    "        AGD_creation_phi_tilde.Phi_tilde1_table[n]=tl.tenalg.mode_dot(AGD_creation_phi_tilde.Phi_tilde1_table[n],Phi[:,sel-1],0)\n",
    "        Phi_tilde1=AGD_creation_phi_tilde.Phi_tilde1_table[n]\n",
    "\n",
    "    #Construction of phi_tilde2\n",
    "    if(sel==0):\n",
    "        AGD_creation_phi_tilde.Phi_tilde2_table[n][N-2]=tl.tenalg.mode_dot(A_tilde[N-2],Phi[:,N-2],0)\n",
    "        for i in range(N-3,-1,-1) :\n",
    "            AGD_creation_phi_tilde.Phi_tilde2_table[n][i]=tl.tenalg.contract(A_tilde[i],2,AGD_creation_phi_tilde.Phi_tilde2_table[n][i+1],0)\n",
    "            AGD_creation_phi_tilde.Phi_tilde2_table[n][i]=tl.tenalg.mode_dot(AGD_creation_phi_tilde.Phi_tilde2_table[n][i],Phi[:,i],0)\n",
    "        Phi_tilde2=AGD_creation_phi_tilde.Phi_tilde2_table[n][0]\n",
    "        \n",
    "    if(sel!=0  and sel!=(N-1)):\n",
    "        Phi_tilde2=AGD_creation_phi_tilde.Phi_tilde2_table[n][sel]\n",
    "\n",
    "    return (Phi_tilde1, Phi_tilde2 )\n",
    "\n",
    "def AGD_calcul_cout_gradient(A,Phi_tilde1,Phi_tilde2,si,y,sel,N):\n",
    "    if(sel==0):\n",
    "        Phi_tilde=np.multiply.outer(si,Phi_tilde2) #Phi_tilde2(alpha1,l) => Phi_tilde(s1,alpha1,l)\n",
    "        fl=tl.tenalg.contract(A,(0,1),Phi_tilde,(0,1))-y # => vecteur de taille l\n",
    "        gradW=tl.tenalg.mode_dot(Phi_tilde,fl,2) # => gradW(s1,alpha1)\n",
    "    elif(sel==N-1):\n",
    "        Phi_tilde=np.multiply.outer(si,Phi_tilde1) #Phi_tilde1(alpha(N-1)) => Phi_tilde(sN,alpha(N-1))\n",
    "        fl=tl.tenalg.contract(A,(0,1),Phi_tilde,(0,1))-y #=> vecteur de taille l\n",
    "        gradW=np.multiply.outer(Phi_tilde,fl) # => gradW(sN,alpha(N-1),l)\n",
    "    else:\n",
    "        Phi_tilde=np.multiply.outer(si,Phi_tilde1) #=> Phi_tilde1(alpha(i-1)) => Phi_tilde1(si,alpha(i-1))\n",
    "        Phi_tilde=np.multiply.outer(Phi_tilde,Phi_tilde2) # Phi_tilde2(alpha(i),l) => Phi_tilde(si,alpha(i-1),alpha(i),l)\n",
    "        fl=tl.tenalg.contract(A,(0,1,2),Phi_tilde,(0,1,2))-y # => vecteur de taille l\n",
    "        gradW=tl.tenalg.mode_dot(Phi_tilde,fl,3) # => gradW(si,alpha(i-1),alpha(i))\n",
    "    cost = sum([i**2 for i in fl])\n",
    "\n",
    "    return ( cost , gradW )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConjugateGradient(A,b,Npass,B,sel,pos0,posL,N,nbTraining,cutoff):\n",
    "    #Computation of the gradient\n",
    "    gradB = DMRG_compute_gradient(A,b,B,sel,pos0,posL,N)\n",
    "\n",
    "    #Initialization of r and p\n",
    "    r=-gradB\n",
    "    p=r\n",
    "\n",
    "    #Computation of the norm of r\n",
    "    if(sel==0 or (sel==1 and sel>pos0) ):\n",
    "        r_prod = tl.tenalg.contract(r,(0,1,2),r,(0,1,2))\n",
    "    elif( (sel==posL-1 and sel< pos0) or (sel==posL and sel> pos0) ):\n",
    "        r_prod = tl.tenalg.contract(r,(0,1,2,3,4),r,(0,1,2,3,4))\n",
    "    elif( (sel==posL and sel< pos0) or (sel==posL+1 and sel > pos0)  ):\n",
    "        r_prod = tl.tenalg.contract(r,(0,1,2,3,4),r,(0,1,2,3,4))\n",
    "    elif( (sel==N-2 and sel<pos0 ) or sel==N-1):\n",
    "        r_prod = tl.tenalg.contract(r,(0,1,2),r,(0,1,2))\n",
    "    else:\n",
    "        r_prod = tl.tenalg.contract(r,(0,1,2,3),r,(0,1,2,3))\n",
    "\n",
    "    #Loop over Npass\n",
    "    for _i in range(Npass): \n",
    "        if _i==0 and tl.norm(r,1) < cutoff :\n",
    "            break\n",
    "        \n",
    "        if(sel==0 or (sel==1 and sel>pos0) ):\n",
    "            Ap = tl.tenalg.contract(A,(0,2,4),p,(0,1,2))\n",
    "            alpha = r_prod/(tl.tenalg.contract(p,(0,1,2),Ap,(0,1,2)))\n",
    "            B = B + alpha*p\n",
    "            r=r-alpha*Ap\n",
    "            rnew_prod = tl.tenalg.contract(r,(0,1,2),r,(0,1,2))\n",
    "            if tl.norm(r,1) < cutoff :\n",
    "                break\n",
    "            p= r + (rnew_prod/r_prod)*p\n",
    "            r_prod = rnew_prod\n",
    "        elif( (sel==posL-1 and sel< pos0) or (sel==posL and sel> pos0) ):\n",
    "            Ap = tl.tenalg.contract(A,(0,2,4,6),p,(0,1,2,3))\n",
    "            alpha = r_prod/(tl.tenalg.contract(p,(0,1,2,3,4),Ap,(0,1,2,3,4)))\n",
    "            B = B + alpha*p\n",
    "            r=r-alpha*Ap\n",
    "            rnew_prod = tl.tenalg.contract(r,(0,1,2,3,4),r,(0,1,2,3,4))\n",
    "            if tl.norm(r,1) < cutoff :\n",
    "                break\n",
    "            p= r + (rnew_prod/r_prod)*p\n",
    "            r_prod = rnew_prod\n",
    "        elif( (sel==posL and sel< pos0) or (sel==posL+1 and sel > pos0)  ):\n",
    "            Ap = tl.tenalg.contract(A,(0,2,4,6),p,(0,1,3,4)).transpose((0,1,4,2,3))\n",
    "            alpha = r_prod/(tl.tenalg.contract(p,(0,1,2,3,4),Ap,(0,1,2,3,4)))\n",
    "            B = B + alpha*p\n",
    "            r=r-alpha*Ap\n",
    "            rnew_prod = tl.tenalg.contract(r,(0,1,2,3,4),r,(0,1,2,3,4))\n",
    "            if tl.norm(r,1) < cutoff :\n",
    "                break\n",
    "            p= r + (rnew_prod/r_prod)*p\n",
    "            r_prod = rnew_prod\n",
    "        elif( (sel==N-2 and sel<pos0 ) or sel==N-1):\n",
    "            Ap = tl.tenalg.contract(A,(0,2,4),p,(0,1,2))\n",
    "            alpha = r_prod/(tl.tenalg.contract(p,(0,1,2),Ap,(0,1,2)))\n",
    "            B = B + alpha*p\n",
    "            r=r-alpha*Ap\n",
    "            rnew_prod = tl.tenalg.contract(r,(0,1,2),r,(0,1,2))\n",
    "            if tl.norm(r,1) < cutoff :\n",
    "                break\n",
    "            p= r + (rnew_prod/r_prod)*p\n",
    "            r_prod = rnew_prod\n",
    "        else:\n",
    "            Ap = tl.tenalg.contract(A,(0,2,4,6),p,(0,1,2,3))\n",
    "            alpha = r_prod/(tl.tenalg.contract(p,(0,1,2,3),Ap,(0,1,2,3)))\n",
    "            B = B + alpha*p\n",
    "            r=r-alpha*Ap\n",
    "            rnew_prod = tl.tenalg.contract(r,(0,1,2,3),r,(0,1,2,3))\n",
    "            if tl.norm(r,1) < cutoff :\n",
    "                break\n",
    "            p= r + (rnew_prod/r_prod)*p\n",
    "            r_prod = rnew_prod\n",
    "    return B\n",
    "\n",
    "def gradient_descent_fixed_stepsize(A,b,B,sel,pos0,posL,N,alpha,nbTraining,cutoff,Npass,Phi_tilde,loss_function,label):\n",
    "    i=0\n",
    "    gradB=0\n",
    "    while( (i==0 or tl.norm(gradB,2) > cutoff ) and i<Npass):\n",
    "        gradB = DMRG_compute_gradient(A,b,B,sel,pos0,posL,N,Phi_tilde,loss_function,label)\n",
    "        B=B-alpha*gradB/nbTraining\n",
    "        i=i+1\n",
    "    return B\n",
    "\n",
    "def Adam(A,b,B,sel,pos0,posL,N,alpha,nbTraining,cutoff,Npass,Phi_tilde,loss_function,label,beta1 = 0.9, beta2 = 0.999,eps=10**(-10)):\n",
    "    i=0\n",
    "    gradB=0 ; vdB = 0; sdB = 0\n",
    "    while( (i==0 or tl.norm(gradB,2) > cutoff ) and i<Npass):\n",
    "        i=i+1\n",
    "        gradB = DMRG_compute_gradient(A,b,B,sel,pos0,posL,N,Phi_tilde,loss_function,label)\n",
    "\n",
    "        # Moving average of the gradients\n",
    "        vdB = beta1*vdB +(1-beta1)*gradB\n",
    "\n",
    "        # Compute bias-corrected first moment estimate\n",
    "        v_cor = vdB/(1-beta1**i)\n",
    "\n",
    "        # Moving average of the squared gradients\n",
    "        sdB = beta2*sdB +(1-beta2)*np.power(gradB,2)\n",
    "\n",
    "        # Compute bias-corrected second raw moment estimate\n",
    "        s_cor = sdB/(1-beta2**i)\n",
    "\n",
    "        # Update parameter\n",
    "        B=B-alpha*v_cor/(np.sqrt(s_cor)+eps)\n",
    "        \n",
    "    return B\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorly as tl\n",
    "\n",
    "def contractMPS(W,Phi): \n",
    "    res=tl.tenalg.mode_dot(W[0],Phi[:,0],0)\n",
    "    if(len(W)>1):\n",
    "        if(len(W[0].shape)==2):\n",
    "            res=tl.tenalg.contract(W[1],1,res,0)\n",
    "        else:\n",
    "            res=tl.tenalg.contract(W[1],1,res,1)\n",
    "        res=tl.tenalg.mode_dot(res,Phi[:,1],0)\n",
    "\n",
    "    #Do all the contractions that are left\n",
    "    for i in range(2,len(W)):\n",
    "        res=tl.tenalg.contract(W[i],1,res,0)  \n",
    "        res=tl.tenalg.mode_dot(res,Phi[:,i],0)\n",
    "\n",
    "    return(res)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #test de la fonction contractMPS\n",
    "    t1=np.array([[1,0],[0,4]])\n",
    "    t2=np.array([[[1,0],[0,1]],[[2,0],[0,0]]])\n",
    "    t3=np.array([[0,1],[2,3]])\n",
    "    p1=np.array([1,0]) ; p2=np.array([0,2]) ; p3=np.array([1,1])\n",
    "    W=[t1,t2,t3]\n",
    "    phi=np.array([p1,p2,p3]).T\n",
    "    print(contractMPS(W,phi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.392856196949378e-24\n",
      "3.378827419855959e-24\n",
      "3.3720855094757386e-24\n",
      "3.362319226708983e-24\n",
      "3.352643840325555e-24\n",
      "3.344059064038399e-24\n",
      "3.338189933202037e-24\n",
      "3.337573937160221e-24\n",
      "3.334982796952632e-24\n",
      "3.3307854123898705e-24\n",
      "[[ 1.00000000e+00 -1.07771864e-14]\n",
      " [ 1.00000000e+00  1.73250303e-12]\n",
      " [ 1.00000000e+00 -4.34730030e-12]\n",
      " [ 1.00000000e+00 -1.26582078e-12]\n",
      " [ 8.88148874e-14  1.00000000e+00]\n",
      " [-8.22508728e-13  1.00000000e+00]\n",
      " [-1.11849419e-12  1.00000000e+00]\n",
      " [-1.29022989e-13  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "class ModelMPS :\n",
    "    def __init__(self,N,diml,W=[]):\n",
    "        self.N=N \n",
    "        self.diml=diml \n",
    "        self.W=W.copy() \n",
    "        self.nbSweep=0\n",
    "\n",
    "    def onesInitialization(self,dimalpha,posL=-1,M=-1,goal=1,data=[],sigma=0):\n",
    "\n",
    "        self.posL = posL\n",
    "\n",
    "        #Computation of M\n",
    "        if(M==-1):\n",
    "            if(len(data)==0):\n",
    "                M=((np.sqrt(3)+0.80)/2)**(self.N)\n",
    "            else:\n",
    "                M=0\n",
    "                for example in data:\n",
    "                    M_ite = np.prod([np.cos(np.pi/2*elem) + np.sin(np.pi/2*elem) for elem in example])\n",
    "                    if M_ite>M:\n",
    "                        M=M_ite\n",
    "\n",
    "        #Computation of the constant value which is equal to all the terms of the tensors of the MPS form\n",
    "        mfact=(goal)**(1/self.N)/(dimalpha**(1-(1/self.N))*M**(1/self.N))\n",
    "\n",
    "        #Initialization of the label index\n",
    "        if(posL==-1):\n",
    "            self.posL=math.floor(self.N/2) #le tenseur qui portera l\n",
    "        \n",
    "        if(self.algo == \"GD\"):\n",
    "            self.posL=self.N-1\n",
    "\n",
    "        #Initialization of tensors\n",
    "        self.W.append(np.ones((2,dimalpha))*mfact+sigma*np.random.randn(2,dimalpha)) #dim1 s(1), dim2 alpha(1) \n",
    "        for i in range(1,self.N-1):\n",
    "            if(i==self.posL):\n",
    "                self.W.append(np.ones((2,dimalpha,dimalpha,self.diml))*mfact+sigma*np.random.randn(2,dimalpha,dimalpha,self.diml)) # dim1 : s(i) , dim2 alpha(i) ,dim3 alpha(i+1) ,dim4 l\n",
    "            else:\n",
    "                self.W.append(np.ones((2,dimalpha,dimalpha))*mfact+sigma*np.random.randn(2,dimalpha,dimalpha)) # dim1 : s(i) , dim2 alpha(i) ,dim3 alpha(i+1)\n",
    "        if(self.algo==\"DMRG\"):\n",
    "            self.W.append(np.ones((2,dimalpha))*mfact+sigma*np.random.randn(2,dimalpha))  # dim1 : s(N) , dim2 alpha(N) \n",
    "        else:\n",
    "            self.W.append(np.ones((2,dimalpha,self.diml))*mfact+sigma*np.random.randn(2,dimalpha,self.diml))  # dim1 : s(N) , dim2 alpha(N) , dim3 l\n",
    "\n",
    "    def normalInitialization(self,dimalpha,mfact=0.95,mu=0,posL=-1):\n",
    "        self.posL = posL\n",
    "\n",
    "        #Initialization of the label index\n",
    "        if(posL==-1):\n",
    "            self.posL=math.floor(self.N/2) #le tenseur qui portera l\n",
    "        \n",
    "        if(self.algo == \"GD\"):\n",
    "            self.posL=self.N-1\n",
    "\n",
    "        #Initialization of tensors\n",
    "        self.W.append(mu+np.random.randn(2,dimalpha)*mfact) #dim1 s(1), dim2 alpha(1) \n",
    "        for i in range(1,self.N-1):\n",
    "            if(i==self.posL and self.algo==\"DMRG\"):\n",
    "                self.W.append(mu+np.random.randn(2,dimalpha,dimalpha,self.diml)*mfact) # dim1 : s(i) , dim2 alpha(i) ,dim3 alpha(i+1) ,dim4 l\n",
    "            else:\n",
    "                self.W.append(mu+np.random.randn(2,dimalpha,dimalpha)*mfact) # dim1 : s(i) , dim2 alpha(i) ,dim3 alpha(i+1)\n",
    "        if(self.algo==\"DMRG\"):\n",
    "            self.W.append(mu+np.random.randn(2,dimalpha)*mfact)  # dim1 : s(N) , dim2 alpha(N)\n",
    "        else:\n",
    "            self.W.append(mu+np.random.randn(2,dimalpha,self.diml)*mfact) # dim1 : s(N) , dim2 alpha(N) , dim3 l\n",
    "\n",
    "    def choose_loss_function(self,loss_function):\n",
    "        self.loss_function = loss_function\n",
    "\n",
    "    def choose_algo(self,algo_name):\n",
    "        self.algo=algo_name\n",
    "    \n",
    "    def choose_optimizer(self,optimizer_name):\n",
    "        self.optimizer = optimizer_name\n",
    "\n",
    "    def trainDMRG(self,data_x,label,alpha=10**(-1),Npass=4,nmethod=1,maxalpha=10,cutoff=10**(-10)):        \n",
    "        #Retrevial of the number of inputs and initialization of the error and all the steps of the algorithm\n",
    "        err=[]\n",
    "        nbTraining = data_x.shape[0]\n",
    "        poss=[i for i in range(0,self.N)] +[i for i in range(0,self.N-1)][::-1]\n",
    "        \n",
    "        #Incrementation of the number of total sweeps\n",
    "        self.nbSweep+=2\n",
    "        \n",
    "        #Loop over all the possibilities/steps\n",
    "        for _e in range(2*(self.N-1)):\n",
    "            #Initialization of the cost of the iteration and the tab which contains all the Phi_tilde\n",
    "            cost=0  \n",
    "            Phi_tilde_tab = []\n",
    "\n",
    "            #Retrevial of impotant parameters of the step\n",
    "            sel=poss.pop(0)\n",
    "            Max=max(sel,poss[0])\n",
    "            Min=min(sel,poss[0])\n",
    "\n",
    "            #Construction of B and A_tilde and also initialization of A and b for the conjugate gradient\n",
    "            (B,A_tilde)=DMRG_creation_B_Atilde(self.W,sel,poss[0])\n",
    "            A=0 ; b=0\n",
    "\n",
    "            #Loop over all the training data\n",
    "            for n in range(nbTraining):\n",
    "\n",
    "                #Flatten the data and compute Phi\n",
    "                img=data_x[n].flatten()\n",
    "                si=phi(img[[Min,Max]]) ; Phi=phi(np.delete(img,(sel,poss[0])))\n",
    "\n",
    "                #Construction of phi_tilde1 and phi_tilde2\n",
    "                (Phi_tilde1,Phi_tilde2) = DMRG_creation_phi_tilde12(A_tilde,Phi,sel,poss[0],n,Min,self.N,nbTraining)\n",
    "\n",
    "                #Construction of An, bn and Phi_tilde\n",
    "                An , bn , Phi_tilde = DMRG_compute_stuff_gradient(Phi_tilde1,Phi_tilde2,si,sel,poss[0],self.posL,self.N,label[n,:])\n",
    "                \n",
    "                #According to the loss function, either the method increments A and b, or it stocks Phi_tilde\n",
    "                if self.loss_function == \"quadratic\":\n",
    "                    A+=An ; b+=bn \n",
    "                elif self.loss_function == \"log-quadratic\" or self.loss_function == \"cross-entropy\":\n",
    "                    Phi_tilde_tab.append(Phi_tilde)\n",
    "\n",
    "                #Computation of the cost\n",
    "                cost += DMRG_compute_cost(B,Phi_tilde,label[n,:],sel,poss[0],self.posL,self.N,self.loss_function)\n",
    "                \n",
    "            #Computation of the total cost of the step\n",
    "            err.append( cost/nbTraining )\n",
    "\n",
    "            #Optimization step\n",
    "            if(self.optimizer==\"GD\"):\n",
    "                B = gradient_descent_fixed_stepsize(A,b,B,sel,poss[0],self.posL,self.N,alpha,nbTraining,cutoff,Npass,Phi_tilde_tab,self.loss_function,label)\n",
    "            elif(self.optimizer==\"CG\"):\n",
    "                B = ConjugateGradient(A,b,Npass,B,sel,poss[0],self.posL,self.N,nbTraining,cutoff)\n",
    "            elif(self.optimizer==\"Adam\"):\n",
    "                B = Adam(A,b,B,sel,poss[0],self.posL,self.N,alpha,nbTraining,cutoff,Npass,Phi_tilde_tab,self.loss_function,label)\n",
    "            \n",
    "            #Computation of the SVD in order to find back the 2 tensors\n",
    "            (self.W[Min],self.W[Max])=SVD_B(sel,poss[0],B,self.posL,self.N,maxalpha,cutoff,nmethod)\n",
    "\n",
    "\n",
    "        return err\n",
    "\n",
    "    def trainAGD(self,data_x,label,alpha):\n",
    "\n",
    "        #Retrevial of the number of inputs and initialization of the error and all the steps of the algorithm\n",
    "        err=[]\n",
    "        nbTraining = data_x.shape[0]\n",
    "\n",
    "        #Incrementation of the number of total sweeps\n",
    "        self.nbSweep+=1\n",
    "\n",
    "        #Loop over all the possibilities/steps\n",
    "        for e in range(self.N):\n",
    "\n",
    "            #Initialization of the cost and the gradient of the iteration \n",
    "            gradW=0\n",
    "            cost=0\n",
    "\n",
    "            #Retrevial of the tensor to be optimized\n",
    "            sel=e%self.N\n",
    "\n",
    "            #Construction of A and A_tilde\n",
    "            A_tilde=self.W.copy() ; A=A_tilde.pop(sel)\n",
    "\n",
    "            #Loop over all the training data\n",
    "            for n in range(nbTraining):\n",
    "                \n",
    "                #Flatten the data and compute Phi\n",
    "                img=data_x[n].flatten()\n",
    "                si=phi(img[sel]) ; Phi=phi(np.delete(img,sel))\n",
    "\n",
    "                #Construction of phi_tilde1 and phi_tilde2\n",
    "                (Phi_tilde1,Phi_tilde2) = AGD_creation_phi_tilde(A_tilde,Phi,sel,n,self.N,nbTraining)\n",
    "\n",
    "                #Computation of the cost and gradient of the step\n",
    "                (cost_ite,grad_ite)=AGD_calcul_cout_gradient(A,Phi_tilde1,Phi_tilde2,si,label[n,:],sel,self.N)\n",
    "                cost+=cost_ite ; gradW+=grad_ite\n",
    "\n",
    "            #Optimization step : A gradient descent step with fixed stepsize\n",
    "            self.W[sel]=self.W[sel]-alpha*gradW/nbTraining\n",
    "\n",
    "            #Computation of the cost\n",
    "            err.append( ((1/2)*cost)/nbTraining )\n",
    "        return err\n",
    "\n",
    "    def train(self,data_x,label,alpha=10**(-1),Npass=4,nmethod=1,maxalpha=10,cutoff=10**(-10)):\n",
    "        if( self.algo == \"GD\"):\n",
    "            return self.trainAGD(data_x,label,alpha=alpha)\n",
    "        elif self.algo == \"DMRG\":\n",
    "            return self.trainDMRG(data_x,label,alpha=alpha,Npass=Npass,nmethod=nmethod,maxalpha=maxalpha,cutoff=cutoff)\n",
    "\n",
    "    def predict(self,data_x):\n",
    "        #Initialization of the list which contains the value of the decision function\n",
    "        pred=[]\n",
    "\n",
    "        #Retrevial of the number of inputs\n",
    "        nbExample = data_x.shape[0]\n",
    "\n",
    "        #Loop over all the data\n",
    "        for i in range(nbExample):\n",
    "\n",
    "            #Flatten the data and compute Phi\n",
    "            img=data_x[i].reshape(-1,)\n",
    "            Phi=phi(img)\n",
    "\n",
    "            #Computation of the value of the decision function\n",
    "            f = contractMPS(self.W,Phi)\n",
    "            if(self.loss_function==\"quadratic\" or self.loss_function==\"log-quadratic\"):\n",
    "                pred.append(f)\n",
    "            elif self.loss_function==\"cross-entropy\":\n",
    "                pred.append(np.exp(f)/sum(np.exp(f)))\n",
    "\n",
    "        return np.array(pred)\n",
    "\n",
    "    def accuracy(self,data_x,label):\n",
    "        #Computation of the prediction\n",
    "        prediction=self.predict(data_x)\n",
    "\n",
    "        #Retrevial of the number of inputs\n",
    "        nbExample=len(prediction)\n",
    "\n",
    "        #Initialization of the counter of good classification\n",
    "        cpt=0\n",
    "\n",
    "        #Loop over all the examples\n",
    "        for example in range(nbExample):\n",
    "\n",
    "            #If the example is well classified, incrementation of the counter\n",
    "            if(np.argmax(prediction[example])==np.argmax(label[example])):\n",
    "                cpt+=1\n",
    "\n",
    "        return cpt/nbExample\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    A = ModelMPS(9,2)\n",
    "    A.choose_algo(\"DMRG\")\n",
    "    A.choose_optimizer(\"CG\")\n",
    "    A.choose_loss_function(\"quadratic\")\n",
    "    A.normalInitialization(5,0.4)\n",
    "    Nt=8 #Nombre de training example\n",
    "    data=np.zeros((Nt,3,3))\n",
    "    \n",
    "    #Carr blanc  gauche\n",
    "    data[0]=np.array([[1,0,0],[1,0,0],[1,0,0]])\n",
    "    data[1]=np.array([[1,0,0],[0,0,0],[0,0,0]])\n",
    "    data[2]=np.array([[0,0,0],[1,0,0],[0,0,0]])\n",
    "    data[3]=np.array([[0,0,0],[0,0,0],[1,0,0]])\n",
    "\n",
    "    #Carr blanc  droite\n",
    "    data[4]=np.array([[0,0,1],[0,0,1],[0,0,1]])\n",
    "    data[5]=np.array([[0,0,1],[0,0,0],[0,0,0]])\n",
    "    data[6]=np.array([[0,0,0],[0,0,1],[0,0,0]])\n",
    "    data[7]=np.array([[0,0,0],[0,0,0],[0,0,1]])\n",
    "\n",
    "    #Creation des labels\n",
    "    y=np.array([[1,0],[1,0],[1,0],[1,0],[0,1],[0,1],[0,1],[0,1]])\n",
    "\n",
    "    err=[]\n",
    "    for epoch in range(10):\n",
    "        err += A.train(data,y,alpha=10**(-1))\n",
    "        print(err[-1])\n",
    "    print(A.predict(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of the model and the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10 #Number of features\n",
    "nbClass = 2 #Number of classes\n",
    "\n",
    "DMRG = ModelMPS(N,nbClass) #Creation of the model\n",
    "\n",
    "DMRG.choose_algo(\"DMRG\") #Choice of the DMRG algorithm\n",
    "\n",
    "DMRG.choose_loss_function(\"quadratic\") #Choice of the quadratic loss function\n",
    "\n",
    "DMRG.choose_optimizer(\"CG\") #Choice of the conjugate gradient method as optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbExample = 50 #Number of examples\n",
    "\n",
    "data,y = make_dataset_random(N,nbExample,nbClass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=5 #Initial bond dimension\n",
    "\n",
    "DMRG.onesInitialization(5,data=data) #Constant initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of the tensor network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contract(tensor1, modes1, tensor2, modes2):\n",
    "    \"\"\"Tensor contraction between two tensors on specified modes\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tensor1 : tl.tensor\n",
    "    modes1 : int list or int\n",
    "        modes on which to contract tensor1\n",
    "    tensor2 : tl.tensor\n",
    "    modes2 : int list or int\n",
    "        modes on which to contract tensor2\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    contraction : tensor1 contracted with tensor2 on the specified modes\n",
    "    \"\"\"\n",
    "    if isinstance(modes1, int):\n",
    "        modes1 = [modes1]\n",
    "    if isinstance(modes2, int):\n",
    "        modes2 = [modes2]\n",
    "    modes1 = list(modes1)\n",
    "    modes2 = list(modes2)\n",
    "    \n",
    "    if len(modes1) != len(modes2):\n",
    "        raise ValueError('Can only contract two tensors along the same number of modes'\n",
    "                         '(len(modes1) == len(modes2))'\n",
    "                         'However, got {} modes for tensor 1 and {} mode for tensor 2'\n",
    "                         '(modes1={}, and modes2={})'.format(\n",
    "                           len(modes1), len(modes2), modes1, modes2))\n",
    "    \n",
    "    contraction_dims = [tl.shape(tensor1)[i] for i in modes1]\n",
    "    if contraction_dims != [tl.shape(tensor2)[i] for i in modes2]:\n",
    "        raise ValueError('Trying to contract tensors over modes of different sizes'\n",
    "                         '(contracting modes of sizes {} and {}'.format(\n",
    "                             contraction_dims, [tl.shape(tensor2)[i] for i in modes2]))\n",
    "    shared_dim = int(np.prod(contraction_dims))\n",
    "\n",
    "    modes1_free = [i for i in range(tl.ndim(tensor1)) if i not in modes1]\n",
    "    free_shape1 = [tl.shape(tensor1)[i] for i in modes1_free]\n",
    "\n",
    "    tensor1 = tl.reshape(tl.transpose(tensor1, modes1_free + modes1),\n",
    "                         (int(np.prod(free_shape1)), shared_dim))\n",
    "    \n",
    "    modes2_free = [i for i in range(tl.ndim(tensor2)) if i not in modes2]\n",
    "    free_shape2 = [tl.shape(tensor2)[i] for i in modes2_free]\n",
    "\n",
    "    tensor2 = tl.reshape(tl.transpose(tensor2, modes2 + modes2_free),\n",
    "                         (shared_dim, int(np.prod(free_shape2))))\n",
    "    \n",
    "    res = tl.dot(tensor1, tensor2)\n",
    "    return tl.reshape(res, tuple(free_shape1 + free_shape2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nbEpoch = 5 #Number of epochs\n",
    "\n",
    "#Training of the model\n",
    "err=[]\n",
    "for _e in range(nbEpoch):\n",
    "    err += DMRG.train(data,y) \n",
    "\n",
    "#Display the evolution of the error\n",
    "sweeps=np.linspace(0,nbEpoch,len(err))\n",
    "plt.plot(sweeps,np.log(err))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\asus\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (1.19.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (0.22.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (50.3.1.post20201107)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in c:\\users\\asus\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.25.11)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorly as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  100.0 %.\n"
     ]
    }
   ],
   "source": [
    "acc = DMRG.accuracy(data,y) #Computation of the accuray\n",
    "\n",
    "print(\"Accuracy : \",acc*100,\"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label = DMRG.predict(data) #Computation of the value of the decision function the inputs of data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
